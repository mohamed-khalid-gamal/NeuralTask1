<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/generate_pdf_report.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/generate_pdf_report.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;PDF Report Generator for Penguin Classification Analysis&#10;Generates a comprehensive PDF report with visualizations and analysis&#10;&quot;&quot;&quot;&#10;&#10;from reportlab.lib.pagesizes import letter, A4&#10;from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle&#10;from reportlab.lib.units import inch&#10;from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, PageBreak, Table, TableStyle&#10;from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_JUSTIFY&#10;from reportlab.lib import colors&#10;from datetime import datetime&#10;import os&#10;&#10;&#10;class PDFReportGenerator:&#10;    &quot;&quot;&quot;Generates comprehensive PDF report for penguin classification analysis&quot;&quot;&quot;&#10;&#10;    def __init__(self, output_dir='report_outputs'):&#10;        self.output_dir = output_dir&#10;        self.pdf_path = os.path.join(output_dir, 'Penguin_Classification_Report.pdf')&#10;&#10;    def create_report(self):&#10;        &quot;&quot;&quot;Create the complete PDF report&quot;&quot;&quot;&#10;        doc = SimpleDocTemplate(&#10;            self.pdf_path,&#10;            pagesize=letter,&#10;            rightMargin=0.5*inch,&#10;            leftMargin=0.5*inch,&#10;            topMargin=0.75*inch,&#10;            bottomMargin=0.5*inch&#10;        )&#10;&#10;        # Container for the 'Flowable' objects&#10;        story = []&#10;&#10;        # Define styles&#10;        styles = getSampleStyleSheet()&#10;&#10;        # Custom styles&#10;        title_style = ParagraphStyle(&#10;            'CustomTitle',&#10;            parent=styles['Heading1'],&#10;            fontSize=24,&#10;            textColor=colors.HexColor('#1f77b4'),&#10;            spaceAfter=30,&#10;            alignment=TA_CENTER,&#10;            fontName='Helvetica-Bold'&#10;        )&#10;&#10;        heading1_style = ParagraphStyle(&#10;            'CustomHeading1',&#10;            parent=styles['Heading1'],&#10;            fontSize=18,&#10;            textColor=colors.HexColor('#2c3e50'),&#10;            spaceAfter=12,&#10;            spaceBefore=12,&#10;            fontName='Helvetica-Bold'&#10;        )&#10;&#10;        heading2_style = ParagraphStyle(&#10;            'CustomHeading2',&#10;            parent=styles['Heading2'],&#10;            fontSize=14,&#10;            textColor=colors.HexColor('#34495e'),&#10;            spaceAfter=10,&#10;            spaceBefore=10,&#10;            fontName='Helvetica-Bold'&#10;        )&#10;&#10;        body_style = ParagraphStyle(&#10;            'CustomBody',&#10;            parent=styles['BodyText'],&#10;            fontSize=11,&#10;            alignment=TA_JUSTIFY,&#10;            spaceAfter=12&#10;        )&#10;&#10;        # Title Page&#10;        story.append(Spacer(1, 1.5*inch))&#10;        story.append(Paragraph(&quot;Penguin Classification Analysis Report&quot;, title_style))&#10;        story.append(Spacer(1, 0.3*inch))&#10;        story.append(Paragraph(&quot;Perceptron and Adaline Algorithm Comparison&quot;, styles['Heading2']))&#10;        story.append(Spacer(1, 0.5*inch))&#10;        story.append(Paragraph(f&quot;Generated on: {datetime.now().strftime('%B %d, %Y')}&quot;, styles['Normal']))&#10;        story.append(PageBreak())&#10;&#10;        # Executive Summary&#10;        story.append(Paragraph(&quot;Executive Summary&quot;, heading1_style))&#10;        story.append(Paragraph(&#10;            &quot;This report presents a comprehensive analysis of binary classification using Perceptron and &quot;&#10;            &quot;Adaline algorithms on the Palmer Penguins dataset. We evaluated multiple feature combinations &quot;&#10;            &quot;across different penguin species pairs to understand classification performance and feature &quot;&#10;            &quot;discriminative power.&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Spacer(1, 0.2*inch))&#10;&#10;        # Add Perceptron Analysis&#10;        story.append(Paragraph(&quot;1. Perceptron Algorithm Analysis&quot;, heading1_style))&#10;        story.append(Paragraph(&#10;            &quot;The Perceptron algorithm is a binary linear classifier that learns a decision boundary to &quot;&#10;            &quot;separate two classes. We tested 10 different combinations of features and class pairs.&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Spacer(1, 0.2*inch))&#10;&#10;        # Good Performance Examples - Perceptron&#10;        story.append(Paragraph(&quot;1.1 High Performance Examples&quot;, heading2_style))&#10;&#10;        # Example 1: Adelie vs Gentoo - CulmenLength vs CulmenDepth&#10;        story = self.add_classification_example(&#10;            story, styles, body_style, heading2_style,&#10;            algorithm=&quot;Perceptron&quot;,&#10;            class1=&quot;Adelie&quot;, class2=&quot;Gentoo&quot;,&#10;            feature1=&quot;CulmenLength&quot;, feature2=&quot;CulmenDepth&quot;,&#10;            train_acc=&quot;98.33%&quot;, test_acc=&quot;100.00%&quot;,&#10;            eta=0.01, epochs=100, use_bias=True,&#10;            analysis=(&#10;                &quot;This combination achieved perfect test accuracy (100%). The decision boundary plot shows &quot;&#10;                &quot;excellent linear separability between Adelie and Gentoo penguins using culmen measurements. &quot;&#10;                &quot;Gentoo penguins typically have longer culmen length but similar culmen depth, creating a &quot;&#10;                &quot;clear separation. The learning curve shows rapid convergence, indicating the classes are &quot;&#10;                &quot;highly separable. The confusion matrix confirms zero misclassifications on the test set.&quot;&#10;            )&#10;        )&#10;&#10;        # Example 2: Adelie vs Chinstrap - CulmenLength vs FlipperLength&#10;        story = self.add_classification_example(&#10;            story, styles, body_style, heading2_style,&#10;            algorithm=&quot;Perceptron&quot;,&#10;            class1=&quot;Adelie&quot;, class2=&quot;Chinstrap&quot;,&#10;            feature1=&quot;CulmenLength&quot;, feature2=&quot;FlipperLength&quot;,&#10;            train_acc=&quot;93.33%&quot;, test_acc=&quot;100.00%&quot;,&#10;            eta=0.01, epochs=100, use_bias=True,&#10;            analysis=(&#10;                &quot;Another excellent result with 100% test accuracy. The combination of culmen length and &quot;&#10;                &quot;flipper length provides strong discrimination between Adelie and Chinstrap species. &quot;&#10;                &quot;Chinstrap penguins tend to have longer flippers relative to their culmen length, enabling &quot;&#10;                &quot;clear separation. The learning curve demonstrates stable convergence with minimal errors.&quot;&#10;            )&#10;        )&#10;&#10;        # Example 3: Adelie vs Gentoo - CulmenDepth vs FlipperLength&#10;        story = self.add_classification_example(&#10;            story, styles, body_style, heading2_style,&#10;            algorithm=&quot;Perceptron&quot;,&#10;            class1=&quot;Adelie&quot;, class2=&quot;Gentoo&quot;,&#10;            feature1=&quot;CulmenDepth&quot;, feature2=&quot;FlipperLength&quot;,&#10;            train_acc=&quot;96.67%&quot;, test_acc=&quot;100.00%&quot;,&#10;            eta=0.01, epochs=100, use_bias=True,&#10;            analysis=(&#10;                &quot;This combination also achieves perfect classification. Gentoo penguins have significantly &quot;&#10;                &quot;longer flippers compared to Adelie penguins, while culmen depth remains relatively similar. &quot;&#10;                &quot;This creates an effective feature space for linear separation. The boundary plot shows &quot;&#10;                &quot;minimal overlap between the two classes.&quot;&#10;            )&#10;        )&#10;&#10;        story.append(PageBreak())&#10;&#10;        # Moderate Performance - Perceptron&#10;        story.append(Paragraph(&quot;1.2 Moderate Performance Examples&quot;, heading2_style))&#10;&#10;        story = self.add_classification_example(&#10;            story, styles, body_style, heading2_style,&#10;            algorithm=&quot;Perceptron&quot;,&#10;            class1=&quot;Chinstrap&quot;, class2=&quot;Gentoo&quot;,&#10;            feature1=&quot;CulmenLength&quot;, feature2=&quot;FlipperLength&quot;,&#10;            train_acc=&quot;85.00%&quot;, test_acc=&quot;82.50%&quot;,&#10;            eta=0.01, epochs=100, use_bias=True,&#10;            analysis=(&#10;                &quot;This combination shows moderate performance with 82.5% test accuracy. While both Chinstrap &quot;&#10;                &quot;and Gentoo have longer culmen lengths compared to Adelie, there is more overlap between &quot;&#10;                &quot;these two species. The decision boundary struggles to perfectly separate all instances, &quot;&#10;                &quot;as evidenced by the confusion matrix showing some misclassifications. The learning curve &quot;&#10;                &quot;indicates the algorithm reached its optimal performance but cannot achieve perfect separation &quot;&#10;                &quot;due to inherent overlap in the feature space.&quot;&#10;            )&#10;        )&#10;&#10;        # Poor Performance - Perceptron&#10;        story.append(Paragraph(&quot;1.3 Poor Performance Examples&quot;, heading2_style))&#10;&#10;        story = self.add_classification_example(&#10;            story, styles, body_style, heading2_style,&#10;            algorithm=&quot;Perceptron&quot;,&#10;            class1=&quot;Adelie&quot;, class2=&quot;Chinstrap&quot;,&#10;            feature1=&quot;FlipperLength&quot;, feature2=&quot;BodyMass&quot;,&#10;            train_acc=&quot;50.00%&quot;, test_acc=&quot;50.00%&quot;,&#10;            eta=0.01, epochs=100, use_bias=True,&#10;            analysis=(&#10;                &quot;This combination performs at chance level (50%), indicating complete failure to learn a &quot;&#10;                &quot;meaningful decision boundary. Adelie and Chinstrap penguins have very similar flipper lengths &quot;&#10;                &quot;and body masses, making these features ineffective for discrimination. The decision boundary &quot;&#10;                &quot;plot shows significant overlap between classes. The learning curve remains flat, confirming &quot;&#10;                &quot;the algorithm cannot find a separating hyperplane. This demonstrates the critical importance &quot;&#10;                &quot;of feature selection in classification tasks.&quot;&#10;            )&#10;        )&#10;&#10;        story.append(PageBreak())&#10;&#10;        # Adaline Analysis&#10;        story.append(Paragraph(&quot;2. Adaline Algorithm Analysis&quot;, heading1_style))&#10;        story.append(Paragraph(&#10;            &quot;Adaline (Adaptive Linear Neuron) is an improvement over the Perceptron that uses gradient descent &quot;&#10;            &quot;to minimize mean squared error. It updates weights based on continuous output rather than binary &quot;&#10;            &quot;predictions, often leading to better convergence behavior.&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Spacer(1, 0.2*inch))&#10;&#10;        # Good Performance Examples - Adaline&#10;        story.append(Paragraph(&quot;2.1 High Performance Examples&quot;, heading2_style))&#10;&#10;        story = self.add_classification_example(&#10;            story, styles, body_style, heading2_style,&#10;            algorithm=&quot;Adaline&quot;,&#10;            class1=&quot;Adelie&quot;, class2=&quot;Gentoo&quot;,&#10;            feature1=&quot;CulmenDepth&quot;, feature2=&quot;FlipperLength&quot;,&#10;            train_acc=&quot;96.67%&quot;, test_acc=&quot;100.00%&quot;,&#10;            eta=0.001, epochs=100, mse_threshold=0.5, use_bias=True,&#10;            analysis=(&#10;                &quot;Adaline achieves perfect test accuracy with this feature combination. The MSE-based learning &quot;&#10;                &quot;approach allows smooth convergence to an optimal decision boundary. The learning curve shows &quot;&#10;                &quot;rapid decrease in mean squared error, indicating efficient learning. The normalized features &quot;&#10;                &quot;help Adaline's gradient descent optimization work effectively. The confusion matrix confirms &quot;&#10;                &quot;perfect classification on the test set.&quot;&#10;            )&#10;        )&#10;&#10;        story = self.add_classification_example(&#10;            story, styles, body_style, heading2_style,&#10;            algorithm=&quot;Adaline&quot;,&#10;            class1=&quot;Chinstrap&quot;, class2=&quot;Gentoo&quot;,&#10;            feature1=&quot;CulmenDepth&quot;, feature2=&quot;BodyMass&quot;,&#10;            train_acc=&quot;93.33%&quot;, test_acc=&quot;97.50%&quot;,&#10;            eta=0.001, epochs=100, mse_threshold=0.5, use_bias=True,&#10;            analysis=(&#10;                &quot;Excellent performance with 97.5% test accuracy. Gentoo penguins have distinctly higher body &quot;&#10;                &quot;mass compared to Chinstrap penguins, combined with differences in culmen depth, these features &quot;&#10;                &quot;provide strong discriminative power. The learning curve shows smooth MSE reduction, &quot;&#10;                &quot;characteristic of Adaline's gradient descent approach. Only one misclassification occurs in &quot;&#10;                &quot;the test set, likely due to an outlier or boundary case.&quot;&#10;            )&#10;        )&#10;&#10;        story = self.add_classification_example(&#10;            story, styles, body_style, heading2_style,&#10;            algorithm=&quot;Adaline&quot;,&#10;            class1=&quot;Chinstrap&quot;, class2=&quot;Gentoo&quot;,&#10;            feature1=&quot;CulmenLength&quot;, feature2=&quot;BodyMass&quot;,&#10;            train_acc=&quot;88.33%&quot;, test_acc=&quot;97.50%&quot;,&#10;            eta=0.001, epochs=100, mse_threshold=0.5, use_bias=True,&#10;            analysis=(&#10;                &quot;Strong generalization performance with test accuracy (97.5%) exceeding training accuracy &quot;&#10;                &quot;(88.33%). This suggests good regularization and the model doesn't overfit. The combination &quot;&#10;                &quot;of culmen length and body mass effectively separates these species, with Gentoo penguins &quot;&#10;                &quot;being significantly larger. The learning curve demonstrates stable convergence.&quot;&#10;            )&#10;        )&#10;&#10;        story.append(PageBreak())&#10;&#10;        # Moderate Performance - Adaline&#10;        story.append(Paragraph(&quot;2.2 Moderate Performance Examples&quot;, heading2_style))&#10;&#10;        story = self.add_classification_example(&#10;            story, styles, body_style, heading2_style,&#10;            algorithm=&quot;Adaline&quot;,&#10;            class1=&quot;Adelie&quot;, class2=&quot;Gentoo&quot;,&#10;            feature1=&quot;FlipperLength&quot;, feature2=&quot;BodyMass&quot;,&#10;            train_acc=&quot;83.33%&quot;, test_acc=&quot;80.00%&quot;,&#10;            eta=0.001, epochs=100, mse_threshold=0.5, use_bias=True,&#10;            analysis=(&#10;                &quot;Moderate performance at 80% test accuracy. While Gentoo penguins are generally larger, there &quot;&#10;                &quot;exists some overlap in the flipper length and body mass ranges with Adelie penguins. The &quot;&#10;                &quot;learning curve shows convergence but at a higher MSE level compared to better-performing &quot;&#10;                &quot;combinations. The confusion matrix reveals several misclassifications, indicating the decision &quot;&#10;                &quot;boundary cannot perfectly separate the classes with these features alone.&quot;&#10;            )&#10;        )&#10;&#10;        # Poor Performance - Adaline&#10;        story.append(Paragraph(&quot;2.3 Poor Performance Examples&quot;, heading2_style))&#10;&#10;        story = self.add_classification_example(&#10;            story, styles, body_style, heading2_style,&#10;            algorithm=&quot;Adaline&quot;,&#10;            class1=&quot;Adelie&quot;, class2=&quot;Chinstrap&quot;,&#10;            feature1=&quot;CulmenLength&quot;, feature2=&quot;CulmenDepth&quot;,&#10;            train_acc=&quot;60.00%&quot;, test_acc=&quot;70.00%&quot;,&#10;            eta=0.001, epochs=100, mse_threshold=0.5, use_bias=True,&#10;            analysis=(&#10;                &quot;Poor performance with only 70% test accuracy. Adelie and Chinstrap penguins have overlapping &quot;&#10;                &quot;culmen measurements, making these features ineffective for separation. The decision boundary &quot;&#10;                &quot;plot shows substantial class overlap. The learning curve shows higher MSE values even after &quot;&#10;                &quot;multiple epochs, indicating difficulty in finding an optimal linear separator. This &quot;&#10;                &quot;demonstrates that not all feature combinations are suitable for linear classification.&quot;&#10;            )&#10;        )&#10;&#10;        story.append(PageBreak())&#10;&#10;        # Comparative Analysis&#10;        story.append(Paragraph(&quot;3. Comparative Analysis&quot;, heading1_style))&#10;&#10;        # Algorithm comparison&#10;        story.append(Paragraph(&quot;3.1 Perceptron vs Adaline&quot;, heading2_style))&#10;        story.append(Paragraph(&#10;            &quot;&lt;b&gt;Convergence Behavior:&lt;/b&gt; Perceptron uses binary threshold updates, while Adaline employs &quot;&#10;            &quot;gradient descent on continuous outputs. Adaline generally shows smoother learning curves with &quot;&#10;            &quot;gradual MSE reduction, whereas Perceptron shows step-wise error reduction.&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Paragraph(&#10;            &quot;&lt;b&gt;Performance:&lt;/b&gt; Both algorithms achieve similar accuracy on highly separable data (100% on &quot;&#10;            &quot;Adelie vs Gentoo). However, Adaline often performs slightly better on moderately separable classes &quot;&#10;            &quot;due to its continuous optimization approach.&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Paragraph(&#10;            &quot;&lt;b&gt;Convergence Speed:&lt;/b&gt; Perceptron may converge faster on perfectly separable data, while Adaline &quot;&#10;            &quot;provides more stable convergence through gradient descent, especially with proper learning rate tuning.&quot;,&#10;            body_style&#10;        ))&#10;&#10;        # Feature Analysis&#10;        story.append(Paragraph(&quot;3.2 Feature Discriminative Power&quot;, heading2_style))&#10;        story.append(Paragraph(&#10;            &quot;&lt;b&gt;Most Discriminative Features:&lt;/b&gt;&quot;,&#10;            body_style&#10;        ))&#10;&#10;        feature_table_data = [&#10;            ['Feature Pair', 'Best Class Pair', 'Accuracy', 'Interpretation'],&#10;            ['CulmenLength + CulmenDepth', 'Adelie vs Gentoo', '100%', 'Excellent separation'],&#10;            ['CulmenLength + FlipperLength', 'Adelie vs Chinstrap', '100%', 'Strong discrimination'],&#10;            ['CulmenDepth + FlipperLength', 'Adelie vs Gentoo', '100%', 'Clear boundaries'],&#10;            ['CulmenDepth + BodyMass', 'Chinstrap vs Gentoo', '97.5%', 'Very good separation'],&#10;            ['FlipperLength + BodyMass', 'Adelie vs Chinstrap', '50-65%', 'Poor separation']&#10;        ]&#10;&#10;        feature_table = Table(feature_table_data, colWidths=[1.8*inch, 1.5*inch, 0.9*inch, 1.8*inch])&#10;        feature_table.setStyle(TableStyle([&#10;            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#3498db')),&#10;            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),&#10;            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),&#10;            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),&#10;            ('FONTSIZE', (0, 0), (-1, 0), 10),&#10;            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),&#10;            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),&#10;            ('GRID', (0, 0), (-1, -1), 1, colors.black),&#10;            ('FONTSIZE', (0, 1), (-1, -1), 9),&#10;        ]))&#10;        story.append(feature_table)&#10;        story.append(Spacer(1, 0.2*inch))&#10;&#10;        # Class Separability&#10;        story.append(Paragraph(&quot;3.3 Class Pair Separability&quot;, heading2_style))&#10;        story.append(Paragraph(&#10;            &quot;&lt;b&gt;Adelie vs Gentoo:&lt;/b&gt; Highly separable across most feature combinations. Gentoo penguins are &quot;&#10;            &quot;significantly larger with longer flippers and distinct culmen measurements, enabling excellent &quot;&#10;            &quot;classification performance (95-100% accuracy).&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Paragraph(&#10;            &quot;&lt;b&gt;Chinstrap vs Gentoo:&lt;/b&gt; Good separability, particularly when using body mass and culmen features. &quot;&#10;            &quot;Gentoo's larger size provides strong discriminative power (85-97.5% accuracy on good feature pairs).&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Paragraph(&#10;            &quot;&lt;b&gt;Adelie vs Chinstrap:&lt;/b&gt; Most challenging separation due to similar physical characteristics. &quot;&#10;            &quot;Performance varies greatly depending on feature selection (50-100% accuracy). Careful feature &quot;&#10;            &quot;engineering is critical for this class pair.&quot;,&#10;            body_style&#10;        ))&#10;&#10;        story.append(PageBreak())&#10;&#10;        # Best Results Summary&#10;        story.append(Paragraph(&quot;4. Highest Accuracy Results&quot;, heading1_style))&#10;        story.append(Paragraph(&#10;            &quot;The following feature combinations achieved the highest classification accuracy:&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Spacer(1, 0.1*inch))&#10;&#10;        best_results_data = [&#10;            ['Rank', 'Algorithm', 'Classes', 'Features', 'Test Accuracy'],&#10;            ['1', 'Perceptron', 'Adelie vs Gentoo', 'CulmenLength + CulmenDepth', '100.00%'],&#10;            ['1', 'Perceptron', 'Adelie vs Chinstrap', 'CulmenLength + FlipperLength', '100.00%'],&#10;            ['1', 'Perceptron', 'Adelie vs Gentoo', 'CulmenDepth + FlipperLength', '100.00%'],&#10;            ['1', 'Adaline', 'Adelie vs Gentoo', 'CulmenDepth + FlipperLength', '100.00%'],&#10;            ['2', 'Adaline', 'Chinstrap vs Gentoo', 'CulmenDepth + BodyMass', '97.50%'],&#10;            ['2', 'Adaline', 'Chinstrap vs Gentoo', 'CulmenLength + BodyMass', '97.50%'],&#10;        ]&#10;&#10;        best_table = Table(best_results_data, colWidths=[0.6*inch, 1.2*inch, 1.6*inch, 2*inch, 1.2*inch])&#10;        best_table.setStyle(TableStyle([&#10;            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#27ae60')),&#10;            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),&#10;            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),&#10;            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),&#10;            ('FONTSIZE', (0, 0), (-1, 0), 10),&#10;            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),&#10;            ('BACKGROUND', (0, 1), (-1, -1), colors.lightgreen),&#10;            ('GRID', (0, 0), (-1, -1), 1, colors.black),&#10;            ('FONTSIZE', (0, 1), (-1, -1), 9),&#10;        ]))&#10;        story.append(best_table)&#10;        story.append(Spacer(1, 0.3*inch))&#10;&#10;        story.append(Paragraph(&#10;            &quot;&lt;b&gt;Key Finding:&lt;/b&gt; Multiple combinations achieved perfect 100% test accuracy, demonstrating that &quot;&#10;            &quot;with proper feature selection, both Perceptron and Adaline can effectively classify penguin species. &quot;&#10;            &quot;The most successful features involve combinations of culmen measurements (length and depth) with &quot;&#10;            &quot;body size indicators (flipper length and body mass).&quot;,&#10;            body_style&#10;        ))&#10;&#10;        # Conclusions&#10;        story.append(Paragraph(&quot;5. Conclusions and Recommendations&quot;, heading1_style))&#10;&#10;        story.append(Paragraph(&quot;&lt;b&gt;5.1 Key Findings:&lt;/b&gt;&quot;, heading2_style))&#10;        story.append(Paragraph(&#10;            &quot;1. &lt;b&gt;Feature Selection is Critical:&lt;/b&gt; Performance varies dramatically (50% to 100%) depending on &quot;&#10;            &quot;feature choice. Culmen measurements combined with body size features work best.&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Paragraph(&#10;            &quot;2. &lt;b&gt;Species-Specific Patterns:&lt;/b&gt; Gentoo penguins are easiest to classify due to their distinctive &quot;&#10;            &quot;size. Adelie vs Chinstrap classification is most challenging.&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Paragraph(&#10;            &quot;3. &lt;b&gt;Algorithm Performance:&lt;/b&gt; Both Perceptron and Adaline achieve comparable accuracy on linearly &quot;&#10;            &quot;separable data. Adaline shows more consistent performance on moderately separable classes.&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Paragraph(&#10;            &quot;4. &lt;b&gt;Linear Separability:&lt;/b&gt; Most species pairs exhibit good linear separability with appropriate &quot;&#10;            &quot;features, validating the use of linear classifiers for this task.&quot;,&#10;            body_style&#10;        ))&#10;&#10;        story.append(Paragraph(&quot;&lt;b&gt;5.2 Recommendations:&lt;/b&gt;&quot;, heading2_style))&#10;        story.append(Paragraph(&#10;            &quot;• For production deployment, use CulmenLength + CulmenDepth or CulmenDepth + FlipperLength features&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Paragraph(&#10;            &quot;• When classifying Adelie vs Chinstrap, prefer CulmenLength + FlipperLength over other combinations&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Paragraph(&#10;            &quot;• Consider Adaline for scenarios requiring smooth convergence and continuous optimization&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Paragraph(&#10;            &quot;• For multi-class problems, implement one-vs-rest approach using the best binary classifiers&quot;,&#10;            body_style&#10;        ))&#10;&#10;        story.append(PageBreak())&#10;&#10;        # Appendix - Full Results&#10;        story.append(Paragraph(&quot;Appendix: Complete Results Summary&quot;, heading1_style))&#10;        story.append(Paragraph(&quot;Detailed accuracy metrics for all tested combinations:&quot;, body_style))&#10;        story.append(Spacer(1, 0.1*inch))&#10;&#10;        # Read the summary file and add it&#10;        summary_path = os.path.join(self.output_dir, 'analysis_summary.txt')&#10;        if os.path.exists(summary_path):&#10;            with open(summary_path, 'r') as f:&#10;                content = f.read()&#10;&#10;            # Format the summary content&#10;            for line in content.split('\n'):&#10;                if line.strip():&#10;                    if line.startswith('='):&#10;                        continue&#10;                    elif line.isupper() or 'RESULTS' in line or 'ANALYSIS' in line:&#10;                        story.append(Paragraph(f&quot;&lt;b&gt;{line}&lt;/b&gt;&quot;, body_style))&#10;                    else:&#10;                        story.append(Paragraph(line, ParagraphStyle(&#10;                            'Mono',&#10;                            parent=styles['Code'],&#10;                            fontSize=9,&#10;                            leftIndent=20&#10;                        )))&#10;&#10;        # Build PDF&#10;        doc.build(story)&#10;        print(f&quot;\n{'='*70}&quot;)&#10;        print(f&quot;PDF Report generated successfully!&quot;)&#10;        print(f&quot;Location: {self.pdf_path}&quot;)&#10;        print(f&quot;{'='*70}\n&quot;)&#10;&#10;        return self.pdf_path&#10;&#10;    def add_classification_example(self, story, styles, body_style, heading_style,&#10;                                   algorithm, class1, class2, feature1, feature2,&#10;                                   train_acc, test_acc, analysis, eta=None, epochs=None,&#10;                                   mse_threshold=None, use_bias=True):&#10;        &quot;&quot;&quot;Add a classification example with images and analysis to the story&quot;&quot;&quot;&#10;&#10;        # Example heading&#10;        story.append(Paragraph(&#10;            f&quot;&lt;b&gt;{class1} vs {class2}: {feature1} + {feature2}&lt;/b&gt;&quot;,&#10;            heading_style&#10;        ))&#10;&#10;        # Performance metrics and hyperparameters&#10;        metrics_text = f&quot;Training Accuracy: {train_acc} | Test Accuracy: {test_acc}&quot;&#10;        story.append(Paragraph(metrics_text, body_style))&#10;&#10;        # Add hyperparameters&#10;        if eta is not None or epochs is not None:&#10;            hyperparam_parts = []&#10;            if eta is not None:&#10;                hyperparam_parts.append(f&quot;Learning Rate (η): {eta}&quot;)&#10;            if epochs is not None:&#10;                hyperparam_parts.append(f&quot;Epochs: {epochs}&quot;)&#10;            if mse_threshold is not None and algorithm == &quot;Adaline&quot;:&#10;                hyperparam_parts.append(f&quot;MSE Threshold: {mse_threshold}&quot;)&#10;            hyperparam_parts.append(f&quot;Bias: {'Yes' if use_bias else 'No'}&quot;)&#10;&#10;            hyperparam_text = &quot; | &quot;.join(hyperparam_parts)&#10;            story.append(Paragraph(f&quot;&lt;i&gt;{hyperparam_text}&lt;/i&gt;&quot;, body_style))&#10;&#10;        story.append(Spacer(1, 0.1*inch))&#10;&#10;        # Image paths&#10;        base_name = f&quot;{algorithm}_{class1}_{class2}_{feature1}_{feature2}&quot;&#10;        boundary_path = os.path.join(self.output_dir, f&quot;{base_name}_boundary.png&quot;)&#10;        learning_path = os.path.join(self.output_dir, f&quot;{base_name}_learning.png&quot;)&#10;        confusion_path = os.path.join(self.output_dir, f&quot;{base_name}_confusion.png&quot;)&#10;&#10;        # Add images if they exist&#10;        img_width = 2.3*inch&#10;        img_height = 1.8*inch&#10;&#10;        images_row = []&#10;        if os.path.exists(boundary_path):&#10;            images_row.append(Image(boundary_path, width=img_width, height=img_height))&#10;        if os.path.exists(learning_path):&#10;            images_row.append(Image(learning_path, width=img_width, height=img_height))&#10;        if os.path.exists(confusion_path):&#10;            images_row.append(Image(confusion_path, width=img_width, height=img_height))&#10;&#10;        if images_row:&#10;            img_table = Table([images_row], colWidths=[img_width]*len(images_row))&#10;            img_table.setStyle(TableStyle([&#10;                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),&#10;                ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),&#10;            ]))&#10;            story.append(img_table)&#10;            story.append(Spacer(1, 0.1*inch))&#10;&#10;        # Analysis&#10;        story.append(Paragraph(&quot;&lt;b&gt;Analysis:&lt;/b&gt;&quot;, body_style))&#10;        story.append(Paragraph(analysis, body_style))&#10;        story.append(Spacer(1, 0.2*inch))&#10;&#10;        return story&#10;&#10;&#10;def main():&#10;    &quot;&quot;&quot;Generate the PDF report&quot;&quot;&quot;&#10;    print(&quot;\nGenerating comprehensive PDF report...&quot;)&#10;    print(&quot;This may take a minute as we compile all visualizations and analysis.\n&quot;)&#10;&#10;    generator = PDFReportGenerator()&#10;    pdf_path = generator.create_report()&#10;&#10;    print(f&quot;You can now open and review the PDF report.&quot;)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;PDF Report Generator for Penguin Classification Analysis&#10;Generates a comprehensive PDF report with visualizations and analysis&#10;&quot;&quot;&quot;&#10;&#10;from reportlab.lib.pagesizes import letter&#10;from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle&#10;from reportlab.lib.units import inch&#10;from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, PageBreak, Table, TableStyle&#10;from reportlab.lib.enums import TA_CENTER, TA_JUSTIFY&#10;from reportlab.lib import colors&#10;from datetime import datetime&#10;import os&#10;import json&#10;&#10;# Use computed results from ReportGenerator&#10;from report_generator import ReportGenerator&#10;&#10;&#10;class PDFReportGenerator:&#10;    &quot;&quot;&quot;Generates comprehensive PDF report for penguin classification analysis&quot;&quot;&quot;&#10;&#10;    def __init__(self, output_dir='report_outputs'):&#10;        self.output_dir = output_dir&#10;        self.pdf_path = os.path.join(output_dir, 'Penguin_Classification_Report.pdf')&#10;        self.results = []&#10;&#10;    def _ensure_analysis_assets(self):&#10;        &quot;&quot;&quot;Ensure results.json and figures exist by running the analysis when needed.&quot;&quot;&quot;&#10;        os.makedirs(self.output_dir, exist_ok=True)&#10;        results_path = os.path.join(self.output_dir, 'results.json')&#10;        if not os.path.exists(results_path):&#10;            # Run the comprehensive analysis to generate assets&#10;            generator = ReportGenerator(output_dir=self.output_dir)&#10;            generator.generate_comprehensive_report()&#10;        # Load results&#10;        with open(results_path, 'r') as f:&#10;            self.results = json.load(f)&#10;&#10;    def _format_pct(self, value):&#10;        try:&#10;            return f&quot;{float(value)*100:.2f}%&quot;&#10;        except Exception:&#10;            return str(value)&#10;&#10;    def _pick_examples(self, algorithm, top_n=2):&#10;        algo_results = [r for r in self.results if r['algorithm'] == algorithm]&#10;        algo_results.sort(key=lambda r: r['test_accuracy'], reverse=True)&#10;&#10;        # High performance&#10;        high = algo_results[:top_n]&#10;&#10;        # Moderate performance (between 0.7 and 0.9)&#10;        moderate = next((r for r in algo_results if 0.7 &lt;= r['test_accuracy'] &lt; 0.9), None)&#10;&#10;        # Poor performance (below 0.7)&#10;        poor = next((r for r in algo_results if r['test_accuracy'] &lt; 0.7), None)&#10;&#10;        return high, moderate, poor&#10;&#10;    def create_report(self):&#10;        &quot;&quot;&quot;Create the complete PDF report&quot;&quot;&quot;&#10;        # Ensure we have up-to-date analysis outputs&#10;        self._ensure_analysis_assets()&#10;&#10;        doc = SimpleDocTemplate(&#10;            self.pdf_path,&#10;            pagesize=letter,&#10;            rightMargin=0.5*inch,&#10;            leftMargin=0.5*inch,&#10;            topMargin=0.75*inch,&#10;            bottomMargin=0.5*inch&#10;        )&#10;&#10;        story = []&#10;        styles = getSampleStyleSheet()&#10;&#10;        # Styles&#10;        title_style = ParagraphStyle(&#10;            'CustomTitle', parent=styles['Heading1'], fontSize=24,&#10;            textColor=colors.HexColor('#1f77b4'), spaceAfter=30, alignment=TA_CENTER,&#10;            fontName='Helvetica-Bold'&#10;        )&#10;        heading1_style = ParagraphStyle(&#10;            'CustomHeading1', parent=styles['Heading1'], fontSize=18,&#10;            textColor=colors.HexColor('#2c3e50'), spaceAfter=12, spaceBefore=12,&#10;            fontName='Helvetica-Bold'&#10;        )&#10;        heading2_style = ParagraphStyle(&#10;            'CustomHeading2', parent=styles['Heading2'], fontSize=14,&#10;            textColor=colors.HexColor('#34495e'), spaceAfter=10, spaceBefore=10,&#10;            fontName='Helvetica-Bold'&#10;        )&#10;        body_style = ParagraphStyle(&#10;            'CustomBody', parent=styles['BodyText'], fontSize=11,&#10;            alignment=TA_JUSTIFY, spaceAfter=12&#10;        )&#10;&#10;        # Title Page&#10;        story.append(Spacer(1, 1.5*inch))&#10;        story.append(Paragraph(&quot;Penguin Classification Analysis Report&quot;, title_style))&#10;        story.append(Spacer(1, 0.3*inch))&#10;        story.append(Paragraph(&quot;Perceptron and Adaline Algorithm Comparison&quot;, styles['Heading2']))&#10;        story.append(Spacer(1, 0.5*inch))&#10;        story.append(Paragraph(f&quot;Generated on: {datetime.now().strftime('%B %d, %Y')}&quot;, styles['Normal']))&#10;        story.append(PageBreak())&#10;&#10;        # Executive Summary&#10;        story.append(Paragraph(&quot;Executive Summary&quot;, heading1_style))&#10;        story.append(Paragraph(&#10;            &quot;This report presents a comprehensive analysis of binary classification using Perceptron and &quot;&#10;            &quot;Adaline algorithms on the Palmer Penguins dataset. We evaluated multiple feature combinations &quot;&#10;            &quot;across different penguin species pairs to understand classification performance and feature &quot;&#10;            &quot;discriminative power.&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Spacer(1, 0.2*inch))&#10;&#10;        # Perceptron Analysis&#10;        story.append(Paragraph(&quot;1. Perceptron Algorithm Analysis&quot;, heading1_style))&#10;        story.append(Paragraph(&#10;            &quot;The Perceptron algorithm is a binary linear classifier that learns a decision boundary to &quot;&#10;            &quot;separate two classes. We tested 10 different combinations of features and class pairs.&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Spacer(1, 0.2*inch))&#10;&#10;        p_high, p_mod, p_poor = self._pick_examples(&quot;Perceptron&quot;)&#10;&#10;        story.append(Paragraph(&quot;1.1 High Performance Examples&quot;, heading2_style))&#10;        for r in p_high:&#10;            story = self.add_classification_example(&#10;                story, styles, body_style, heading2_style,&#10;                algorithm=r['algorithm'],&#10;                class1=r['class1'], class2=r['class2'],&#10;                feature1=r['feature1'], feature2=r['feature2'],&#10;                train_acc=self._format_pct(r['train_accuracy']),&#10;                test_acc=self._format_pct(r['test_accuracy']),&#10;                eta=r.get('learning_rate'), epochs=r.get('max_epochs'), use_bias=r.get('use_bias', True),&#10;                analysis=(&#10;                    &quot;High accuracy indicates strong linear separability for this feature pair. The learning &quot;&#10;                    &quot;curve shows rapid convergence and the confusion matrix confirms very few or zero &quot;&#10;                    &quot;misclassifications on the test set.&quot;&#10;                )&#10;            )&#10;        story.append(PageBreak())&#10;&#10;        story.append(Paragraph(&quot;1.2 Moderate Performance Examples&quot;, heading2_style))&#10;        if p_mod:&#10;            r = p_mod&#10;            story = self.add_classification_example(&#10;                story, styles, body_style, heading2_style,&#10;                algorithm=r['algorithm'],&#10;                class1=r['class1'], class2=r['class2'],&#10;                feature1=r['feature1'], feature2=r['feature2'],&#10;                train_acc=self._format_pct(r['train_accuracy']),&#10;                test_acc=self._format_pct(r['test_accuracy']),&#10;                eta=r.get('learning_rate'), epochs=r.get('max_epochs'), use_bias=r.get('use_bias', True),&#10;                analysis=(&#10;                    &quot;Moderate performance suggests some overlap between classes in the selected feature space. &quot;&#10;                    &quot;The decision boundary cannot perfectly separate all points, resulting in a few &quot;&#10;                    &quot;misclassifications.&quot;&#10;                )&#10;            )&#10;        else:&#10;            story.append(Paragraph(&quot;No moderate examples found; most pairs were either highly separable or poor.&quot;, body_style))&#10;        story.append(PageBreak())&#10;&#10;        story.append(Paragraph(&quot;1.3 Poor Performance Examples&quot;, heading2_style))&#10;        if p_poor:&#10;            r = p_poor&#10;            story = self.add_classification_example(&#10;                story, styles, body_style, heading2_style,&#10;                algorithm=r['algorithm'],&#10;                class1=r['class1'], class2=r['class2'],&#10;                feature1=r['feature1'], feature2=r['feature2'],&#10;                train_acc=self._format_pct(r['train_accuracy']),&#10;                test_acc=self._format_pct(r['test_accuracy']),&#10;                eta=r.get('learning_rate'), epochs=r.get('max_epochs'), use_bias=r.get('use_bias', True),&#10;                analysis=(&#10;                    &quot;Low accuracy indicates that the classes are not linearly separable in this feature space. &quot;&#10;                    &quot;The learning curve typically flattens and the confusion matrix shows many &quot;&#10;                    &quot;misclassifications. Consider different features or a non-linear model.&quot;&#10;                )&#10;            )&#10;        else:&#10;            story.append(Paragraph(&quot;No poor examples found in this run.&quot;, body_style))&#10;        story.append(PageBreak())&#10;&#10;        # Adaline Analysis&#10;        story.append(Paragraph(&quot;2. Adaline Algorithm Analysis&quot;, heading1_style))&#10;        story.append(Paragraph(&#10;            &quot;Adaline (Adaptive Linear Neuron) uses gradient descent to minimize mean squared error with &quot;&#10;            &quot;continuous outputs, often giving smoother convergence than Perceptron.&quot;,&#10;            body_style&#10;        ))&#10;        story.append(Spacer(1, 0.2*inch))&#10;&#10;        a_high, a_mod, a_poor = self._pick_examples(&quot;Adaline&quot;)&#10;&#10;        story.append(Paragraph(&quot;2.1 High Performance Examples&quot;, heading2_style))&#10;        for r in a_high:&#10;            story = self.add_classification_example(&#10;                story, styles, body_style, heading2_style,&#10;                algorithm=r['algorithm'],&#10;                class1=r['class1'], class2=r['class2'],&#10;                feature1=r['feature1'], feature2=r['feature2'],&#10;                train_acc=self._format_pct(r['train_accuracy']),&#10;                test_acc=self._format_pct(r['test_accuracy']),&#10;                eta=r.get('learning_rate'), epochs=r.get('max_epochs'), mse_threshold=r.get('mse_threshold'),&#10;                use_bias=r.get('use_bias', True),&#10;                analysis=(&#10;                    &quot;Excellent results with smooth MSE decrease. Feature normalization helps gradient descent &quot;&#10;                    &quot;converge efficiently, resulting in a well-placed decision boundary.&quot;&#10;                )&#10;            )&#10;        story.append(PageBreak())&#10;&#10;        story.append(Paragraph(&quot;2.2 Moderate Performance Examples&quot;, heading2_style))&#10;        if a_mod:&#10;            r = a_mod&#10;            story = self.add_classification_example(&#10;                story, styles, body_style, heading2_style,&#10;                algorithm=r['algorithm'],&#10;                class1=r['class1'], class2=r['class2'],&#10;                feature1=r['feature1'], feature2=r['feature2'],&#10;                train_acc=self._format_pct(r['train_accuracy']),&#10;                test_acc=self._format_pct(r['test_accuracy']),&#10;                eta=r.get('learning_rate'), epochs=r.get('max_epochs'), mse_threshold=r.get('mse_threshold'),&#10;                use_bias=r.get('use_bias', True),&#10;                analysis=(&#10;                    &quot;Moderate results suggest partial overlap in feature distributions. Tuning learning rate &quot;&#10;                    &quot;or selecting more discriminative features may help.&quot;&#10;                )&#10;            )&#10;        else:&#10;            story.append(Paragraph(&quot;No moderate examples found; most pairs were either highly separable or poor.&quot;, body_style))&#10;        story.append(PageBreak())&#10;&#10;        story.append(Paragraph(&quot;2.3 Poor Performance Examples&quot;, heading2_style))&#10;        if a_poor:&#10;            r = a_poor&#10;            story = self.add_classification_example(&#10;                story, styles, body_style, heading2_style,&#10;                algorithm=r['algorithm'],&#10;                class1=r['class1'], class2=r['class2'],&#10;                feature1=r['feature1'], feature2=r['feature2'],&#10;                train_acc=self._format_pct(r['train_accuracy']),&#10;                test_acc=self._format_pct(r['test_accuracy']),&#10;                eta=r.get('learning_rate'), epochs=r.get('max_epochs'), mse_threshold=r.get('mse_threshold'),&#10;                use_bias=r.get('use_bias', True),&#10;                analysis=(&#10;                    &quot;Low accuracy indicates difficulty minimizing MSE due to non-separable classes. Consider &quot;&#10;                    &quot;different features or non-linear models.&quot;&#10;                )&#10;            )&#10;        else:&#10;            story.append(Paragraph(&quot;No poor examples found in this run.&quot;, body_style))&#10;        story.append(PageBreak())&#10;&#10;        # Comparative Analysis&#10;        story.append(Paragraph(&quot;3. Comparative Analysis&quot;, heading1_style))&#10;        story.append(Paragraph(&quot;3.1 Perceptron vs Adaline&quot;, heading2_style))&#10;        story.append(Paragraph(&#10;            &quot;Convergence: Perceptron updates via binary thresholds; Adaline minimizes continuous MSE via &quot;&#10;            &quot;gradient descent, yielding smoother learning curves.&quot;, body_style))&#10;        story.append(Paragraph(&#10;            &quot;Performance: On linearly separable data, both achieve high accuracy. Adaline can be slightly &quot;&#10;            &quot;more stable on moderately separable data due to continuous optimization.&quot;, body_style))&#10;        story.append(Paragraph(&#10;            &quot;Convergence Speed: Perceptron may converge faster when data are perfectly separable; Adaline is &quot;&#10;            &quot;more stable with proper learning rate tuning.&quot;, body_style))&#10;&#10;        # Feature Analysis (dynamic bests)&#10;        story.append(Paragraph(&quot;3.2 Top Performing Feature Pairs&quot;, heading2_style))&#10;        all_sorted = sorted(self.results, key=lambda r: r['test_accuracy'], reverse=True)&#10;        top_rows = [['Rank', 'Algorithm', 'Classes', 'Features', 'Test Accuracy']]&#10;        for idx, r in enumerate(all_sorted[:6], start=1):&#10;            top_rows.append([&#10;                str(idx), r['algorithm'], f&quot;{r['class1']} vs {r['class2']}&quot;,&#10;                f&quot;{r['feature1']} + {r['feature2']}&quot;, self._format_pct(r['test_accuracy'])&#10;            ])&#10;        best_table = Table(top_rows, colWidths=[0.6*inch, 1.2*inch, 1.6*inch, 2*inch, 1.2*inch])&#10;        best_table.setStyle(TableStyle([&#10;            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#27ae60')),&#10;            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),&#10;            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),&#10;            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),&#10;            ('FONTSIZE', (0, 0), (-1, 0), 10),&#10;            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),&#10;            ('BACKGROUND', (0, 1), (-1, -1), colors.lightgreen),&#10;            ('GRID', (0, 0), (-1, -1), 1, colors.black),&#10;            ('FONTSIZE', (0, 1), (-1, -1), 9),&#10;        ]))&#10;        story.append(best_table)&#10;        story.append(PageBreak())&#10;&#10;        # Appendix - Full Results&#10;        story.append(Paragraph(&quot;4. Appendix: Complete Results Summary&quot;, heading1_style))&#10;        story.append(Paragraph(&quot;Detailed accuracy metrics for all tested combinations:&quot;, body_style))&#10;        story.append(Spacer(1, 0.1*inch))&#10;&#10;        # Read the summary file and add it&#10;        summary_path = os.path.join(self.output_dir, 'analysis_summary.txt')&#10;        if os.path.exists(summary_path):&#10;            with open(summary_path, 'r') as f:&#10;                content = f.read()&#10;&#10;            for line in content.split('\n'):&#10;                if line.strip():&#10;                    if line.startswith('='):&#10;                        continue&#10;                    elif line.isupper() or 'RESULTS' in line or 'ANALYSIS' in line:&#10;                        story.append(Paragraph(f&quot;&lt;b&gt;{line}&lt;/b&gt;&quot;, body_style))&#10;                    else:&#10;                        story.append(Paragraph(line, ParagraphStyle(&#10;                            'Mono', parent=styles['Code'], fontSize=9, leftIndent=20&#10;                        )))&#10;&#10;        # Build PDF&#10;        doc.build(story)&#10;        print(f&quot;\n{'='*70}&quot;)&#10;        print(f&quot;PDF Report generated successfully!&quot;)&#10;        print(f&quot;Location: {self.pdf_path}&quot;)&#10;        print(f&quot;{'='*70}\n&quot;)&#10;&#10;        return self.pdf_path&#10;&#10;    def add_classification_example(self, story, styles, body_style, heading_style,&#10;                                   algorithm, class1, class2, feature1, feature2,&#10;                                   train_acc, test_acc, analysis, eta=None, epochs=None,&#10;                                   mse_threshold=None, use_bias=True):&#10;        &quot;&quot;&quot;Add a classification example with images and analysis to the story&quot;&quot;&quot;&#10;&#10;        # Example heading&#10;        story.append(Paragraph(&#10;            f&quot;&lt;b&gt;{class1} vs {class2}: {feature1} + {feature2}&lt;/b&gt;&quot;,&#10;            heading_style&#10;        ))&#10;&#10;        # Performance metrics and hyperparameters&#10;        metrics_text = f&quot;Training Accuracy: {train_acc} | Test Accuracy: {test_acc}&quot;&#10;        story.append(Paragraph(metrics_text, body_style))&#10;&#10;        # Add hyperparameters&#10;        if eta is not None or epochs is not None:&#10;            hyperparam_parts = []&#10;            if eta is not None:&#10;                hyperparam_parts.append(f&quot;Learning Rate (η): {eta}&quot;)&#10;            if epochs is not None:&#10;                hyperparam_parts.append(f&quot;Epochs: {epochs}&quot;)&#10;            if mse_threshold is not None and algorithm == &quot;Adaline&quot;:&#10;                hyperparam_parts.append(f&quot;MSE Threshold: {mse_threshold}&quot;)&#10;            hyperparam_parts.append(f&quot;Bias: {'Yes' if use_bias else 'No'}&quot;)&#10;&#10;            hyperparam_text = &quot; | &quot;.join(hyperparam_parts)&#10;            story.append(Paragraph(f&quot;&lt;i&gt;{hyperparam_text}&lt;/i&gt;&quot;, body_style))&#10;&#10;        story.append(Spacer(1, 0.1*inch))&#10;&#10;        # Image paths&#10;        base_name = f&quot;{algorithm}_{class1}_{class2}_{feature1}_{feature2}&quot;&#10;        boundary_path = os.path.join(self.output_dir, f&quot;{base_name}_boundary.png&quot;)&#10;        learning_path = os.path.join(self.output_dir, f&quot;{base_name}_learning.png&quot;)&#10;        confusion_path = os.path.join(self.output_dir, f&quot;{base_name}_confusion.png&quot;)&#10;&#10;        # Add images if they exist&#10;        img_width = 2.3*inch&#10;        img_height = 1.8*inch&#10;&#10;        images_row = []&#10;        if os.path.exists(boundary_path):&#10;            images_row.append(Image(boundary_path, width=img_width, height=img_height))&#10;        if os.path.exists(learning_path):&#10;            images_row.append(Image(learning_path, width=img_width, height=img_height))&#10;        if os.path.exists(confusion_path):&#10;            images_row.append(Image(confusion_path, width=img_width, height=img_height))&#10;&#10;        if images_row:&#10;            img_table = Table([images_row], colWidths=[img_width]*len(images_row))&#10;            img_table.setStyle(TableStyle([&#10;                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),&#10;                ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),&#10;            ]))&#10;            story.append(img_table)&#10;            story.append(Spacer(1, 0.1*inch))&#10;&#10;        # Analysis&#10;        story.append(Paragraph(&quot;&lt;b&gt;Analysis:&lt;/b&gt;&quot;, body_style))&#10;        story.append(Paragraph(analysis, body_style))&#10;        story.append(Spacer(1, 0.2*inch))&#10;&#10;        return story&#10;&#10;&#10;def main():&#10;    &quot;&quot;&quot;Generate the PDF report&quot;&quot;&quot;&#10;    print(&quot;\nGenerating comprehensive PDF report...&quot;)&#10;    print(&quot;This may take a minute as we compile all visualizations and analysis.\n&quot;)&#10;&#10;    generator = PDFReportGenerator()&#10;    pdf_path = generator.create_report()&#10;&#10;    print(f&quot;You can now open and review the PDF report.&quot;)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/report_generator.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/report_generator.py" />
              <option name="originalContent" value="&#10;import matplotlib.pyplot as plt&#10;from data_preprocessing import DataPreprocessor&#10;from perceptron import Perceptron&#10;from adaline import Adaline&#10;from evaluation import Evaluator&#10;from visualization import Visualizer&#10;import os&#10;&#10;&#10;class ReportGenerator:&#10;&#10;    def __init__(self, output_dir='report_outputs'):&#10;        self.preprocessor = DataPreprocessor()&#10;        self.preprocessor.preprocess()&#10;        self.output_dir = output_dir&#10;&#10;        if not os.path.exists(output_dir):&#10;            os.makedirs(output_dir)&#10;&#10;        self.results = []&#10;&#10;    def test_combination(self, class1, class2, feature1, feature2, algorithm='Perceptron',&#10;                        eta=0.01, epochs=100, mse_threshold=0.01, use_bias=True):&#10;&#10;        print(f&quot;\n{'='*70}&quot;)&#10;        print(f&quot;Testing: {algorithm}&quot;)&#10;        print(f&quot;Classes: {class1} vs {class2}&quot;)&#10;        print(f&quot;Features: {feature1} vs {feature2}&quot;)&#10;        print(f&quot;{'='*70}&quot;)&#10;&#10;        normalize = (algorithm == 'Adaline')&#10;        X, y = self.preprocessor.get_class_data(class1, class2, feature1, feature2, normalize=normalize)&#10;        X_train, X_test, y_train, y_test = self.preprocessor.split_data(X, y, train_size=30, random_state=42)&#10;&#10;        if algorithm == 'Perceptron':&#10;            model = Perceptron(learning_rate=eta, n_epochs=epochs,&#10;                             use_bias=use_bias, random_state=42)&#10;        else:&#10;            model = Adaline(learning_rate=eta, n_epochs=epochs,&#10;                          mse_threshold=mse_threshold, use_bias=use_bias,&#10;                          random_state=42)&#10;&#10;        model.fit(X_train, y_train)&#10;&#10;        y_train_pred = model.predict(X_train)&#10;        y_test_pred = model.predict(X_test)&#10;&#10;        train_acc = Evaluator.accuracy(y_train, y_train_pred)&#10;        test_acc = Evaluator.accuracy(y_test, y_test_pred)&#10;&#10;        cm_train = Evaluator.confusion_matrix(y_train, y_train_pred)&#10;        cm_test = Evaluator.confusion_matrix(y_test, y_test_pred)&#10;&#10;        print(f&quot;\nTraining Accuracy: {train_acc*100:.2f}%&quot;)&#10;        print(f&quot;Test Accuracy: {test_acc*100:.2f}%&quot;)&#10;&#10;        combo_name = f&quot;{algorithm}_{class1}_{class2}_{feature1}_{feature2}&quot;&#10;&#10;        fig1 = Visualizer.plot_decision_boundary(&#10;            X_train, y_train, X_test, y_test, model,&#10;            feature1, feature2, class1, class2, algorithm&#10;        )&#10;        fig1.savefig(f&quot;{self.output_dir}/{combo_name}_boundary.png&quot;, dpi=300, bbox_inches='tight')&#10;        plt.close(fig1)&#10;&#10;        fig2 = Visualizer.plot_learning_curve(model, algorithm)&#10;        fig2.savefig(f&quot;{self.output_dir}/{combo_name}_learning.png&quot;, dpi=300, bbox_inches='tight')&#10;        plt.close(fig2)&#10;&#10;        fig3 = Visualizer.plot_confusion_matrix(cm_test, class1, class2, algorithm)&#10;        fig3.savefig(f&quot;{self.output_dir}/{combo_name}_confusion.png&quot;, dpi=300, bbox_inches='tight')&#10;        plt.close(fig3)&#10;&#10;        result = {&#10;            'algorithm': algorithm,&#10;            'class1': class1,&#10;            'class2': class2,&#10;            'feature1': feature1,&#10;            'feature2': feature2,&#10;            'train_accuracy': train_acc,&#10;            'test_accuracy': test_acc,&#10;            'cm_test': cm_test,&#10;            'epochs_run': len(model.errors_per_epoch if algorithm=='Perceptron' else model.mse_per_epoch),&#10;            'converged': test_acc &gt; 0.8,&#10;            'learning_rate': eta,&#10;            'max_epochs': epochs,&#10;            'mse_threshold': mse_threshold,&#10;            'use_bias': use_bias&#10;        }&#10;&#10;        self.results.append(result)&#10;        return result&#10;&#10;    def generate_comprehensive_report(self):&#10;&#10;        features = ['CulmenLength', 'CulmenDepth', 'FlipperLength', 'OriginLocation', 'BodyMass']&#10;&#10;        combinations = [&#10;            ('Adelie', 'Gentoo', 'CulmenLength', 'CulmenDepth'),&#10;            ('Adelie', 'Gentoo', 'FlipperLength', 'BodyMass'),&#10;            ('Chinstrap', 'Gentoo', 'CulmenLength', 'FlipperLength'),&#10;            ('Adelie', 'Chinstrap', 'FlipperLength', 'BodyMass'),&#10;&#10;            ('Adelie', 'Chinstrap', 'CulmenLength', 'CulmenDepth'),&#10;            ('Adelie', 'Gentoo', 'OriginLocation', 'BodyMass'),&#10;            ('Chinstrap', 'Gentoo', 'CulmenDepth', 'BodyMass'),&#10;&#10;            ('Adelie', 'Chinstrap', 'CulmenLength', 'FlipperLength'),&#10;            ('Adelie', 'Gentoo', 'CulmenDepth', 'FlipperLength'),&#10;            ('Chinstrap', 'Gentoo', 'CulmenLength', 'BodyMass'),&#10;        ]&#10;&#10;        print(&quot;\n&quot; + &quot;=&quot;*70)&#10;        print(&quot;PERCEPTRON ALGORITHM ANALYSIS&quot;)&#10;        print(&quot;=&quot;*70)&#10;&#10;        for combo in combinations:&#10;            self.test_combination(*combo, algorithm='Perceptron', eta=0.01, epochs=100)&#10;&#10;        print(&quot;\n&quot; + &quot;=&quot;*70)&#10;        print(&quot;ADALINE ALGORITHM ANALYSIS&quot;)&#10;        print(&quot;=&quot;*70)&#10;&#10;        for combo in combinations:&#10;            self.test_combination(*combo, algorithm='Adaline', eta=0.001, epochs=100, mse_threshold=0.5)&#10;&#10;        self.generate_summary_report()&#10;&#10;    def generate_summary_report(self):&#10;        with open(f&quot;{self.output_dir}/analysis_summary.txt&quot;, 'w') as f:&#10;            f.write(&quot;=&quot;*80 + &quot;\n&quot;)&#10;            f.write(&quot;PENGUIN CLASSIFICATION - ANALYSIS REPORT\n&quot;)&#10;            f.write(&quot;=&quot;*80 + &quot;\n\n&quot;)&#10;&#10;            f.write(&quot;PERCEPTRON ALGORITHM RESULTS\n&quot;)&#10;            f.write(&quot;-&quot;*80 + &quot;\n&quot;)&#10;            perceptron_results = [r for r in self.results if r['algorithm'] == 'Perceptron']&#10;            perceptron_results.sort(key=lambda x: x['test_accuracy'], reverse=True)&#10;&#10;            for i, r in enumerate(perceptron_results, 1):&#10;                f.write(f&quot;\n{i}. {r['class1']} vs {r['class2']} | {r['feature1']} vs {r['feature2']}\n&quot;)&#10;                f.write(f&quot;   Train Accuracy: {r['train_accuracy']*100:.2f}%\n&quot;)&#10;                f.write(f&quot;   Test Accuracy: {r['test_accuracy']*100:.2f}%\n&quot;)&#10;                f.write(f&quot;   Epochs: {r['epochs_run']}/{r['max_epochs']}\n&quot;)&#10;                f.write(f&quot;   Learning Rate: {r['learning_rate']}\n&quot;)&#10;                f.write(f&quot;   Use Bias: {r['use_bias']}\n&quot;)&#10;                f.write(f&quot;   Performance: {'GOOD' if r['test_accuracy'] &gt; 0.85 else 'MODERATE' if r['test_accuracy'] &gt; 0.7 else 'POOR'}\n&quot;)&#10;&#10;            f.write(&quot;\n\n&quot; + &quot;=&quot;*80 + &quot;\n&quot;)&#10;            f.write(&quot;ADALINE ALGORITHM RESULTS\n&quot;)&#10;            f.write(&quot;-&quot;*80 + &quot;\n&quot;)&#10;            adaline_results = [r for r in self.results if r['algorithm'] == 'Adaline']&#10;            adaline_results.sort(key=lambda x: x['test_accuracy'], reverse=True)&#10;&#10;            for i, r in enumerate(adaline_results, 1):&#10;                f.write(f&quot;\n{i}. {r['class1']} vs {r['class2']} | {r['feature1']} vs {r['feature2']}\n&quot;)&#10;                f.write(f&quot;   Train Accuracy: {r['train_accuracy']*100:.2f}%\n&quot;)&#10;                f.write(f&quot;   Test Accuracy: {r['test_accuracy']*100:.2f}%\n&quot;)&#10;                f.write(f&quot;   Epochs: {r['epochs_run']}/{r['max_epochs']}\n&quot;)&#10;                f.write(f&quot;   Learning Rate: {r['learning_rate']}\n&quot;)&#10;                f.write(f&quot;   MSE Threshold: {r['mse_threshold']}\n&quot;)&#10;                f.write(f&quot;   Use Bias: {r['use_bias']}\n&quot;)&#10;                f.write(f&quot;   Performance: {'GOOD' if r['test_accuracy'] &gt; 0.85 else 'MODERATE' if r['test_accuracy'] &gt; 0.7 else 'POOR'}\n&quot;)&#10;&#10;            f.write(&quot;\n\n&quot; + &quot;=&quot;*80 + &quot;\n&quot;)&#10;            f.write(&quot;BEST FEATURE COMBINATIONS (HIGHEST ACCURACY)\n&quot;)&#10;            f.write(&quot;-&quot;*80 + &quot;\n&quot;)&#10;&#10;            all_results = sorted(self.results, key=lambda x: x['test_accuracy'], reverse=True)&#10;            for i, r in enumerate(all_results[:5], 1):&#10;                f.write(f&quot;\n{i}. {r['algorithm']}: {r['class1']} vs {r['class2']}\n&quot;)&#10;                f.write(f&quot;   Features: {r['feature1']} vs {r['feature2']}\n&quot;)&#10;                f.write(f&quot;   Test Accuracy: {r['test_accuracy']*100:.2f}%\n&quot;)&#10;&#10;            f.write(&quot;\n\n&quot; + &quot;=&quot;*80 + &quot;\n&quot;)&#10;            f.write(&quot;KEY INSIGHTS AND ANALYSIS\n&quot;)&#10;            f.write(&quot;-&quot;*80 + &quot;\n\n&quot;)&#10;&#10;            f.write(&quot;1. FEATURE DISCRIMINATION:\n&quot;)&#10;            f.write(&quot;   - FlipperLength and BodyMass show strong discriminative power\n&quot;)&#10;            f.write(&quot;   - CulmenLength and CulmenDepth are effective for certain class pairs\n&quot;)&#10;            f.write(&quot;   - OriginLocation provides geographical context\n\n&quot;)&#10;&#10;            f.write(&quot;2. CLASS SEPARABILITY:\n&quot;)&#10;            f.write(&quot;   - Gentoo vs Adelie: Generally highly separable\n&quot;)&#10;            f.write(&quot;   - Gentoo vs Chinstrap: Good separability\n&quot;)&#10;            f.write(&quot;   - Adelie vs Chinstrap: More challenging separation\n\n&quot;)&#10;&#10;            f.write(&quot;3. ALGORITHM COMPARISON:\n&quot;)&#10;            f.write(&quot;   - Perceptron: Fast convergence, binary classification\n&quot;)&#10;            f.write(&quot;   - Adaline: Smooth learning, MSE-based optimization\n&quot;)&#10;            f.write(&quot;   - Both achieve similar accuracy on linearly separable data\n\n&quot;)&#10;&#10;            f.write(&quot;4. CONVERGENCE BEHAVIOR:\n&quot;)&#10;            f.write(&quot;   - Well-separated classes converge in fewer epochs\n&quot;)&#10;            f.write(&quot;   - Learning rate affects convergence speed\n&quot;)&#10;            f.write(&quot;   - Some combinations require higher epochs for convergence\n\n&quot;)&#10;&#10;        print(f&quot;\nSummary report saved to: {self.output_dir}/analysis_summary.txt&quot;)&#10;&#10;&#10;def main():&#10;    print(&quot;Starting comprehensive analysis...&quot;)&#10;    print(&quot;This will generate visualizations and analysis for multiple combinations.&quot;)&#10;    print(&quot;Please wait...\n&quot;)&#10;&#10;    generator = ReportGenerator()&#10;    generator.generate_comprehensive_report()&#10;&#10;    print(&quot;\n&quot; + &quot;=&quot;*70)&#10;    print(&quot;ANALYSIS COMPLETE!&quot;)&#10;    print(f&quot;All outputs saved to: {generator.output_dir}/&quot;)&#10;    print(&quot;=&quot;*70)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;" />
              <option name="updatedContent" value="import matplotlib.pyplot as plt&#10;from data_preprocessing import DataPreprocessor&#10;from perceptron import Perceptron&#10;from adaline import Adaline&#10;from evaluation import Evaluator&#10;from visualization import Visualizer&#10;import os&#10;import json&#10;&#10;&#10;class ReportGenerator:&#10;&#10;    def __init__(self, output_dir='report_outputs'):&#10;        self.preprocessor = DataPreprocessor()&#10;        self.preprocessor.preprocess()&#10;        self.output_dir = output_dir&#10;&#10;        if not os.path.exists(output_dir):&#10;            os.makedirs(output_dir)&#10;&#10;        self.results = []&#10;&#10;    def test_combination(self, class1, class2, feature1, feature2, algorithm='Perceptron',&#10;                        eta=0.01, epochs=100, mse_threshold=0.01, use_bias=True):&#10;&#10;        print(f&quot;\n{'='*70}&quot;)&#10;        print(f&quot;Testing: {algorithm}&quot;)&#10;        print(f&quot;Classes: {class1} vs {class2}&quot;)&#10;        print(f&quot;Features: {feature1} vs {feature2}&quot;)&#10;        print(f&quot;{'='*70}&quot;)&#10;&#10;        normalize = (algorithm == 'Adaline')&#10;        X, y = self.preprocessor.get_class_data(class1, class2, feature1, feature2, normalize=normalize)&#10;        # Ensure deterministic split to match GUI and PDF outputs&#10;        X_train, X_test, y_train, y_test = self.preprocessor.split_data(X, y, train_size=30, random_state=42)&#10;&#10;        if algorithm == 'Perceptron':&#10;            model = Perceptron(learning_rate=eta, n_epochs=epochs,&#10;                             use_bias=use_bias, random_state=42)&#10;        else:&#10;            model = Adaline(learning_rate=eta, n_epochs=epochs,&#10;                          mse_threshold=mse_threshold, use_bias=use_bias,&#10;                          random_state=42)&#10;&#10;        model.fit(X_train, y_train)&#10;&#10;        y_train_pred = model.predict(X_train)&#10;        y_test_pred = model.predict(X_test)&#10;&#10;        train_acc = Evaluator.accuracy(y_train, y_train_pred)&#10;        test_acc = Evaluator.accuracy(y_test, y_test_pred)&#10;&#10;        cm_train = Evaluator.confusion_matrix(y_train, y_train_pred)&#10;        cm_test = Evaluator.confusion_matrix(y_test, y_test_pred)&#10;&#10;        print(f&quot;\nTraining Accuracy: {train_acc*100:.2f}%&quot;)&#10;        print(f&quot;Test Accuracy: {test_acc*100:.2f}%&quot;)&#10;&#10;        combo_name = f&quot;{algorithm}_{class1}_{class2}_{feature1}_{feature2}&quot;&#10;&#10;        fig1 = Visualizer.plot_decision_boundary(&#10;            X_train, y_train, X_test, y_test, model,&#10;            feature1, feature2, class1, class2, algorithm&#10;        )&#10;        fig1.savefig(f&quot;{self.output_dir}/{combo_name}_boundary.png&quot;, dpi=300, bbox_inches='tight')&#10;        plt.close(fig1)&#10;&#10;        fig2 = Visualizer.plot_learning_curve(model, algorithm)&#10;        fig2.savefig(f&quot;{self.output_dir}/{combo_name}_learning.png&quot;, dpi=300, bbox_inches='tight')&#10;        plt.close(fig2)&#10;&#10;        fig3 = Visualizer.plot_confusion_matrix(cm_test, class1, class2, algorithm)&#10;        fig3.savefig(f&quot;{self.output_dir}/{combo_name}_confusion.png&quot;, dpi=300, bbox_inches='tight')&#10;        plt.close(fig3)&#10;&#10;        # Cast to native Python types to ensure JSON serializable&#10;        test_acc_float = float(test_acc)&#10;        train_acc_float = float(train_acc)&#10;        epochs_run = int(len(model.errors_per_epoch if algorithm=='Perceptron' else model.mse_per_epoch))&#10;&#10;        result = {&#10;            'algorithm': str(algorithm),&#10;            'class1': str(class1),&#10;            'class2': str(class2),&#10;            'feature1': str(feature1),&#10;            'feature2': str(feature2),&#10;            'combo_name': str(combo_name),&#10;            'train_accuracy': train_acc_float,&#10;            'test_accuracy': test_acc_float,&#10;            'cm_test': cm_test.tolist() if hasattr(cm_test, 'tolist') else cm_test,&#10;            'epochs_run': epochs_run,&#10;            'converged': bool(test_acc_float &gt; 0.8),&#10;            'learning_rate': float(eta),&#10;            'max_epochs': int(epochs),&#10;            'mse_threshold': float(mse_threshold),&#10;            'use_bias': bool(use_bias)&#10;        }&#10;&#10;        self.results.append(result)&#10;        return result&#10;&#10;    def generate_comprehensive_report(self):&#10;&#10;        features = ['CulmenLength', 'CulmenDepth', 'FlipperLength', 'OriginLocation', 'BodyMass']&#10;&#10;        combinations = [&#10;            ('Adelie', 'Gentoo', 'CulmenLength', 'CulmenDepth'),&#10;            ('Adelie', 'Gentoo', 'FlipperLength', 'BodyMass'),&#10;            ('Chinstrap', 'Gentoo', 'CulmenLength', 'FlipperLength'),&#10;            ('Adelie', 'Chinstrap', 'FlipperLength', 'BodyMass'),&#10;&#10;            ('Adelie', 'Chinstrap', 'CulmenLength', 'CulmenDepth'),&#10;            ('Adelie', 'Gentoo', 'OriginLocation', 'BodyMass'),&#10;            ('Chinstrap', 'Gentoo', 'CulmenDepth', 'BodyMass'),&#10;&#10;            ('Adelie', 'Chinstrap', 'CulmenLength', 'FlipperLength'),&#10;            ('Adelie', 'Gentoo', 'CulmenDepth', 'FlipperLength'),&#10;            ('Chinstrap', 'Gentoo', 'CulmenLength', 'BodyMass'),&#10;        ]&#10;&#10;        print(&quot;\n&quot; + &quot;=&quot;*70)&#10;        print(&quot;PERCEPTRON ALGORITHM ANALYSIS&quot;)&#10;        print(&quot;=&quot;*70)&#10;&#10;        for combo in combinations:&#10;            self.test_combination(*combo, algorithm='Perceptron', eta=0.01, epochs=100)&#10;&#10;        print(&quot;\n&quot; + &quot;=&quot;*70)&#10;        print(&quot;ADALINE ALGORITHM ANALYSIS&quot;)&#10;        print(&quot;=&quot;*70)&#10;&#10;        for combo in combinations:&#10;            self.test_combination(*combo, algorithm='Adaline', eta=0.001, epochs=100, mse_threshold=0.5)&#10;&#10;        # Persist results for downstream consumers (e.g., PDF report)&#10;        results_path = os.path.join(self.output_dir, 'results.json')&#10;        with open(results_path, 'w') as f:&#10;            json.dump(self.results, f, indent=2)&#10;&#10;        self.generate_summary_report()&#10;&#10;    def generate_summary_report(self):&#10;        with open(f&quot;{self.output_dir}/analysis_summary.txt&quot;, 'w') as f:&#10;            f.write(&quot;=&quot;*80 + &quot;\n&quot;)&#10;            f.write(&quot;PENGUIN CLASSIFICATION - ANALYSIS REPORT\n&quot;)&#10;            f.write(&quot;=&quot;*80 + &quot;\n\n&quot;)&#10;&#10;            f.write(&quot;PERCEPTRON ALGORITHM RESULTS\n&quot;)&#10;            f.write(&quot;-&quot;*80 + &quot;\n&quot;)&#10;            perceptron_results = [r for r in self.results if r['algorithm'] == 'Perceptron']&#10;            perceptron_results.sort(key=lambda x: x['test_accuracy'], reverse=True)&#10;&#10;            for i, r in enumerate(perceptron_results, 1):&#10;                f.write(f&quot;\n{i}. {r['class1']} vs {r['class2']} | {r['feature1']} vs {r['feature2']}\n&quot;)&#10;                f.write(f&quot;   Train Accuracy: {r['train_accuracy']*100:.2f}%\n&quot;)&#10;                f.write(f&quot;   Test Accuracy: {r['test_accuracy']*100:.2f}%\n&quot;)&#10;                f.write(f&quot;   Epochs: {r['epochs_run']}/{r['max_epochs']}\n&quot;)&#10;                f.write(f&quot;   Learning Rate: {r['learning_rate']}\n&quot;)&#10;                f.write(f&quot;   Use Bias: {r['use_bias']}\n&quot;)&#10;                f.write(f&quot;   Performance: {'GOOD' if r['test_accuracy'] &gt; 0.85 else 'MODERATE' if r['test_accuracy'] &gt; 0.7 else 'POOR'}\n&quot;)&#10;&#10;            f.write(&quot;\n\n&quot; + &quot;=&quot;*80 + &quot;\n&quot;)&#10;            f.write(&quot;ADALINE ALGORITHM RESULTS\n&quot;)&#10;            f.write(&quot;-&quot;*80 + &quot;\n&quot;)&#10;            adaline_results = [r for r in self.results if r['algorithm'] == 'Adaline']&#10;            adaline_results.sort(key=lambda x: x['test_accuracy'], reverse=True)&#10;&#10;            for i, r in enumerate(adaline_results, 1):&#10;                f.write(f&quot;\n{i}. {r['class1']} vs {r['class2']} | {r['feature1']} vs {r['feature2']}\n&quot;)&#10;                f.write(f&quot;   Train Accuracy: {r['train_accuracy']*100:.2f}%\n&quot;)&#10;                f.write(f&quot;   Test Accuracy: {r['test_accuracy']*100:.2f}%\n&quot;)&#10;                f.write(f&quot;   Epochs: {r['epochs_run']}/{r['max_epochs']}\n&quot;)&#10;                f.write(f&quot;   Learning Rate: {r['learning_rate']}\n&quot;)&#10;                f.write(f&quot;   MSE Threshold: {r['mse_threshold']}\n&quot;)&#10;                f.write(f&quot;   Use Bias: {r['use_bias']}\n&quot;)&#10;                f.write(f&quot;   Performance: {'GOOD' if r['test_accuracy'] &gt; 0.85 else 'MODERATE' if r['test_accuracy'] &gt; 0.7 else 'POOR'}\n&quot;)&#10;&#10;            f.write(&quot;\n\n&quot; + &quot;=&quot;*80 + &quot;\n&quot;)&#10;            f.write(&quot;BEST FEATURE COMBINATIONS (HIGHEST ACCURACY)\n&quot;)&#10;            f.write(&quot;-&quot;*80 + &quot;\n&quot;)&#10;&#10;            all_results = sorted(self.results, key=lambda x: x['test_accuracy'], reverse=True)&#10;            for i, r in enumerate(all_results[:5], 1):&#10;                f.write(f&quot;\n{i}. {r['algorithm']}: {r['class1']} vs {r['class2']}\n&quot;)&#10;                f.write(f&quot;   Features: {r['feature1']} vs {r['feature2']}\n&quot;)&#10;                f.write(f&quot;   Test Accuracy: {r['test_accuracy']*100:.2f}%\n&quot;)&#10;&#10;            f.write(&quot;\n\n&quot; + &quot;=&quot;*80 + &quot;\n&quot;)&#10;            f.write(&quot;KEY INSIGHTS AND ANALYSIS\n&quot;)&#10;            f.write(&quot;-&quot;*80 + &quot;\n\n&quot;)&#10;&#10;            f.write(&quot;1. FEATURE DISCRIMINATION:\n&quot;)&#10;            f.write(&quot;   - FlipperLength and BodyMass show strong discriminative power\n&quot;)&#10;            f.write(&quot;   - CulmenLength and CulmenDepth are effective for certain class pairs\n&quot;)&#10;            f.write(&quot;   - OriginLocation provides geographical context\n\n&quot;)&#10;&#10;            f.write(&quot;2. CLASS SEPARABILITY:\n&quot;)&#10;            f.write(&quot;   - Gentoo vs Adelie: Generally highly separable\n&quot;)&#10;            f.write(&quot;   - Gentoo vs Chinstrap: Good separability\n&quot;)&#10;            f.write(&quot;   - Adelie vs Chinstrap: More challenging separation\n\n&quot;)&#10;&#10;            f.write(&quot;3. ALGORITHM COMPARISON:\n&quot;)&#10;            f.write(&quot;   - Perceptron: Fast convergence, binary classification\n&quot;)&#10;            f.write(&quot;   - Adaline: Smooth learning, MSE-based optimization\n&quot;)&#10;            f.write(&quot;   - Both achieve similar accuracy on linearly separable data\n\n&quot;)&#10;&#10;            f.write(&quot;4. CONVERGENCE BEHAVIOR:\n&quot;)&#10;            f.write(&quot;   - Well-separated classes converge in fewer epochs\n&quot;)&#10;            f.write(&quot;   - Learning rate affects convergence speed\n&quot;)&#10;            f.write(&quot;   - Some combinations require higher epochs for convergence\n\n&quot;)&#10;&#10;        print(f&quot;\nSummary report saved to: {self.output_dir}/analysis_summary.txt&quot;)&#10;&#10;&#10;def main():&#10;    print(&quot;Starting comprehensive analysis...&quot;)&#10;    print(&quot;This will generate visualizations and analysis for multiple combinations.&quot;)&#10;    print(&quot;Please wait...\n&quot;)&#10;&#10;    generator = ReportGenerator()&#10;    generator.generate_comprehensive_report()&#10;&#10;    print(&quot;\n&quot; + &quot;=&quot;*70)&#10;    print(&quot;ANALYSIS COMPLETE!&quot;)&#10;    print(f&quot;All outputs saved to: {generator.output_dir}/&quot;)&#10;    print(&quot;=&quot;*70)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>